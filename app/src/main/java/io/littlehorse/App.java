/*
 * This Java source file was generated by the Gradle 'init' task.
 */
package io.littlehorse;

import java.util.ArrayList;
import java.util.Properties;
import java.util.concurrent.ExecutionException;
import org.apache.kafka.clients.admin.NewTopic;
import org.apache.kafka.common.serialization.Serdes;
import org.apache.kafka.streams.KafkaStreams;
import org.apache.kafka.streams.StreamsBuilder;
import org.apache.kafka.streams.StreamsConfig;
import org.apache.kafka.streams.Topology;
import org.apache.kafka.streams.kstream.Consumed;
import org.apache.kafka.streams.kstream.KStream;
import io.littlehorse.common.LHConfig;
import io.littlehorse.common.LHConstants;
import io.littlehorse.common.model.POSTable;
import io.littlehorse.common.model.meta.TaskDef;
import io.littlehorse.common.model.meta.WfSpec;
import io.littlehorse.scheduler.Scheduler;
import io.littlehorse.scheduler.model.WfRunState;
import io.littlehorse.scheduler.serde.WFRunSerde;
import io.littlehorse.server.Server;
import io.littlehorse.worker.TestWorker;

public class App {
    public static void doIdempotentSetup(LHConfig config)
    throws InterruptedException, ExecutionException {
        System.out.println("Creating topics!!");

        ArrayList<NewTopic> topics = new ArrayList<>();
        for (int i = 1; i < 11; i++) {
            topics.add(new NewTopic(
                "task" + i, config.getTaskPartitions(), config.getReplicationFactor()
            ));
        }

        topics.add(new NewTopic(
            POSTable.getRequestTopicName(WfSpec.class),
            3, config.getReplicationFactor()
        ));

        topics.add(new NewTopic(
            POSTable.getRequestTopicName(TaskDef.class),
            3, config.getReplicationFactor()
        ));

        topics.add(new NewTopic(
            LHConstants.WF_RUN_OBSERVABILITY_TOPIC,
            config.getClusterPartitions(),
            config.getReplicationFactor())
        );

        topics.add(new NewTopic(
            LHConstants.WF_RUN_EVENT_TOPIC,
            config.getClusterPartitions(),
            config.getReplicationFactor())
        );

        for (NewTopic topic: topics) {
            config.createKafkaTopic(topic);
        }
        System.out.println("Done creating topics");

    }

    public static void main(String[] args)
    throws InterruptedException, ExecutionException {
        String arg = args[0];
        if (arg.equals("tester")) {
            tester();
            System.exit(0);
        }

        LHConfig config = new LHConfig();
        doIdempotentSetup(config);

        if (arg.equals("worker")) {
            TestWorker.doMain(config);
        } else if (arg.equals("scheduler")) {
            Scheduler.doMain(config);
        } else if (arg.equals("server")) {
            Server.doMain(config);
        }
    }

    // public static void  schedulerAndServer(LHConfig config) {
    //     Topology topology = Scheduler.initTopology(config);
    //     KafkaStreams scheduler = new KafkaStreams(topology, config.getStreamsConfig());

    //     ApiStreamsContext context = new ApiStreamsContext(config, serverStreams);
    //     LHApi api = new LHApi(config, context);

    //     Runtime.getRuntime().addShutdownHook(new Thread(() -> {
    //         scheduler.close();
    //         config.cleanup();
    //     }));

    //     scheduler.start();
    //     api.start();
    // }

    public static void tester() {
        LHConfig config = new LHConfig();
        System.out.println(config.getHostInfo().toString());
    }
}
