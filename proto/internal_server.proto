// Timer-related stuff
syntax = "proto3";
package littlehorse;

option java_multiple_files = true;
option java_package = "io.littlehorse.common.proto";

import "google/protobuf/timestamp.proto";
import "lh-proto/proto/service.proto";


// This section contains data structures used internally for sending the results of
// processing Commands. As a refresher, we need to send the result of processing
// over the network because, if Server A receives a request to idempotently run a
// WfRun with id='foo', but id='foo' partition is assigned to Server B, we need
// to do the processing on server B. Therefore, Server A sends the request over
// Kafka to Server B's partition, and then waits for Server B to process the
// request. Server B uses the data structures below to communicate that result
// back to server A.

message CommandResultPb {
    string command_id = 1;
    google.protobuf.Timestamp result_time = 2;
    bytes result = 3;
}

// The section below contains the protocol for inter-broker communication
enum StoreQueryStatusPb {
    RSQ_OK = 0; // If OK and bytes is empty, means that the key is not found.
    RSQ_NOT_AVAILABLE = 2; // Can't query store, eg. during a rebalance or if migrated.
}

message CentralStoreQueryReplyPb {
    StoreQueryStatusPb code = 1;
    optional bytes result = 2;
    int64 approximate_lag = 3;
}

message CentralStoreQueryPb {
    message CentralStoreSubQueryPb {
        oneof query {
            string key = 1;
            string last_from_prefix = 2;
        }
    }
    bool enable_stale_stores = 1;
    optional int32 specific_partition = 2;
    CentralStoreSubQueryPb query = 3;
    string store = 4;
}

message WaitForCommandPb {
    string command_id = 1;
}

message WaitForCommandReplyPb {
    StoreQueryStatusPb code = 1;
    optional CommandResultPb result = 2;
    optional string message = 3;
}


// This section defines structures used for paginated scan interactive queries. This
// is useful when we want to do things like "Get all nodeRuns for a given wfRun" or
// "find all Variable objects with type=STR, name='email', and value='foo@bar.com'"

enum ScanResultTypePb {
    // Just return the IDs of the objects.
    OBJECT_ID = 0;

    // Return the objects themselves. This can only be done for the object id prefix
    // scan type.
    OBJECT = 1;
}

message PartitionBookmarkPb { // used for paginated responses
    int32 parttion = 1;
    optional string last_key = 2;
}

message BookmarkPb { // Used for paginated responses
    map<int32, PartitionBookmarkPb> in_progress_partitions = 1;
    repeated int32 completed_partitions = 2;
}

message InternalScanPb {
    message TagPrefixScanPb {
        repeated AttributePb attributes = 1;
        // TODO: Add time-based filters here.
        // Note that each Tag has a timestamp at the end of it--that's what
        // we will utilize.
        optional google.protobuf.Timestamp earliest_create_time = 2;
        optional google.protobuf.Timestamp latest_create_time = 3;
    }

    message BoundedObjectIdScanPb {
        string start_object_id = 1;
        optional string end_object_id = 2;
    }

    ScanResultTypePb result_type = 1;
    int32 limit = 2;
    optional BookmarkPb bookmark = 3;
    GETableClassEnumPb object_type = 4;
    string store_name = 5;

    optional string partition_key = 6;

    oneof scan_boundary {
        BoundedObjectIdScanPb bounded_object_id_scan = 7;
        TagPrefixScanPb local_tag_prefix_scan = 8;
    }
}

message InternalScanReplyPb {
    StoreQueryStatusPb code = 1;

    // The type of 'result' depends on the query.
    repeated bytes results = 2;

    // If there are more results (i.e. we hit the limit), then updated_bookmark
    // is set. Otherwise, it is null.
    BookmarkPb updated_bookmark = 3;

    optional string message = 4;
}

// This is used to communicate about different available listeners. Kafka Streams
// provides a way to get info about the host for each other Streams instance.
// However, that Host:
// a) is internal to Kubernetes and
// b) points to the internal listener, not the public listener.
//
// When a Task Worker connects to one LH Server via the bootstrap url (i.e. the
// K8s service that points to all LH Servers), it needs to discover individual
// endpoints for each LH Server.
//
// Each LH Server has multiple advertised listeners for Task Workers. For example,
// the general configuration will have one external listener, which can be accessed
// over Ingress (eg. via Istio Ingressgateway and DNS), and one internal listener,
// which only works for clients in the same kubernetes cluster.
//
// Each listener (eg public/k8s-internal) has a name assigned to it. The Task Worker
// is configured to use a certain listener name based on which network it's in.
// The LHPublicApi grpc method 'registerTaskWorkerPb' takes in a Listener Name
// and returns listeners for all LH Servers.
//
// This endpoint is used to help the LHPublicApi get info about each of the LH
// Servers so that it can formulate the response described above.
message InternalGetAdvertisedHostsPb {}

message InternalGetAdvertisedHostsReplyPb {
    map<string, HostInfoPb> hosts = 1;
}

service LHInternals {
    rpc CentralStoreQuery(CentralStoreQueryPb) returns (CentralStoreQueryReplyPb) {}
    rpc InternalScan(InternalScanPb) returns (InternalScanReplyPb) {}

    rpc waitForCommand(WaitForCommandPb) returns (WaitForCommandReplyPb) {}

    rpc GetAdvertisedHosts(InternalGetAdvertisedHostsPb) returns (InternalGetAdvertisedHostsReplyPb) {}
}

// Stuff for the metrics topology
message TaskMetricUpdatePb {
    google.protobuf.Timestamp window_start = 1;
    MetricsWindowLengthPb type = 2;
    int64 num_entries = 3;
    int64 schedule_to_start_max = 4;
    int64 schedule_to_start_total = 5;
    int64 start_to_complete_max = 6;
    int64 start_to_complete_total = 7;
    int64 total_completed = 8;
    int64 total_errored = 9;
    int64 total_started = 10;

    string task_def_name = 11;
    int64 total_scheduled = 12;
}

message WfMetricUpdatePb {
    google.protobuf.Timestamp window_start = 1;
    MetricsWindowLengthPb type = 2;
    int64 num_entries = 3;
    int64 start_to_complete_max = 6;
    int64 start_to_complete_total = 7;
    int64 total_completed = 8;
    int64 total_errored = 9;
    int64 total_started = 10;

    string wf_spec_name = 11;
    int32 wf_spec_version = 12;
}

message RepartitionCommandPb {
    google.protobuf.Timestamp time = 1;
    optional string command_id = 2;
    oneof repartition_command {
        TaskMetricUpdatePb task_metric_update = 3;
        WfMetricUpdatePb wf_metric_update = 4;
    }
}

// Stuff for Index (internal to the store)
enum GETableClassEnumPb {
    TASK_DEF = 0;
    EXTERNAL_EVENT_DEF = 1;
    WF_SPEC = 2;
    WF_RUN = 3;
    NODE_RUN = 4;
    VARIABLE = 5;
    EXTERNAL_EVENT = 6;
    TASK_DEF_METRICS = 7;
    WF_SPEC_METRICS = 8;
    TASK_WORKER_GROUP = 9;
}

message AttributePb {
    string key = 1;
    string val = 2;
}

enum TagStorageTypePb {
    LOCAL_UNCOUNTED = 0;
    LOCAL_COUNTED = 1;
    LOCAL_HASH_UNCOUNTED = 2;
    REMOTE_HASH_UNCOUNTED = 3;
}

message TagPb {
    // The following info is also stored in the key of the Tag in the store.
    GETableClassEnumPb object_type = 1;
    repeated AttributePb attributes = 2;
    string described_object_id = 3;
    google.protobuf.Timestamp created = 4;

    // The following is not stored in the key.
    TagStorageTypePb tag_type = 5;

    // Observation: it's possible that we could optimize by removing fields 1-4
    // and only relying upon the store key. However, that would complicate
    // the code a bit and may just be premature optimization.
}

message TagsCachePb {
    repeated string tag_ids = 1;
}

message DiscreteTagLocalCounterPb {
    int64 local_count = 1;
    string tag_attributes = 2;
    int32 partition = 3;
}

message TagChangesToBroadcastPb {
    map<string, DiscreteTagLocalCounterPb> changelog = 1;
    int32 partition = 2;
}

/*
For certain discrete tags, eg. "Node Run Status", there may be objects scattered
across different partitions which satisfy the tag.

Sometimes we want to find all of those objects, or find a count of them. For example,
we may be interested in finding all SCHEDULED (but not started) NodeRun's, or we
may want to know how many total failed NodeRun's there are.

We could implement that by repartitioning tags according to the tag value, and then
storing tags in their own separate store. That way, all of the tag entries for
the tag that means "This NodeRun is scheduled but not started" end up on the same
node.

However, this implementation causes a problem: there will be hot partitions. For
high-traffic TaskDef's, there will be too many tag updates to be kept up with on
that processor.

What's the other option? We store tags locally on the same partition that their
parent object lives. But now we need a way to know which partition has how many tags
of each type. What do I mean by this?

Well, let's say we're looking for SCHEDULED NodeRun's, and there's 2 instances, each
with one partition (for simplicity). Instance 1 has partition 1, Instance 2 has
partition 2. Consider the following scenario:
- There's only one SCHEDULED NodeRun, and it lives on Instance 2.
- Instance 1 receives a PollTaskRequest.
- Instance 1 sees that it has no SCHEDULED NodeRun's.
- However, if Instance 1 could know that Partition 2 has 1 scheduled NodeRun, then
  it could just refer the request to Instance 2, and we'd get what we need.

The way we broadcast that information to all instances is through a Global State
Store.

The entries in that state store are simple:
KEY: f"{counter name}_{partition_number}"
VAL: Number of objects that satisfy that counter on the partition number.

Naively, we might want to send an update to the global state store every time a
counter changes. However, that would again mean that every tag gets processed on
a single node (actually, each tag gets processed on all nodes, which is worse).

So what we do is suppress the updates and have a punctuator send them on a periodic
interval (eg. probably going to start with 100ms).


Lastly, a note on what the TagsCachePb is:
When we update or delete a GETable object, the tags for that object may change.
Some may be deleted (eg. when a NodeRun's status changes to RUNNING, we want to
remove the "SCHEDULED" tag), and some may be added (eg. add the "RUNNING" tag).

We need the TagsCachePb to keep track of the tags associated with the Object *before*
the update, so that we can delete any tags that are no longer valid.
*/

// TODO: Some of the stuff in these proto's can be inferred from the store keys.
// I left them in the proto's because it's easier to understand and to implement,
// but we may want to optimize that for performance later on.



// This section defines the "Command"
message WfRunRequestPb {
    optional string wf_run_id = 1;
    string wf_spec_id = 2;
    map<string, VariableValuePb> variables = 3;
}

message TaskClaimEventPb {
    string wf_run_id = 1;
    int32 thread_run_number = 2;
    int32 task_run_number = 3;
    int32 task_run_position = 4;
    google.protobuf.Timestamp time = 5;
    string task_worker_id = 6;
    optional string task_worker_version = 7;
}

message ExternalEventNodeTimeoutPb {
    string wf_run_id = 1;
    int32 thread_run_number = 2;
    int32 node_run_position = 3;
    google.protobuf.Timestamp time = 4;
}

// This section contains commands that originate from the gRPC api. Perhaps they
// could also go in service.proto...?

message SleepNodeMaturedPb {
    string wf_run_id = 1;
    int32 thread_run_number = 2;
    int32 node_run_position = 3;
}

// This is the schema of everything that flows through the Central Command topic.
message CommandPb {
    google.protobuf.Timestamp time = 1;
    optional string command_id = 2;
    oneof command {
        TaskResultEventPb task_result_event = 3;
        TaskClaimEventPb task_claim_event = 4;
        PutWfSpecPb put_wf_spec = 6;
        PutTaskDefPb put_task_def = 7;
        PutExternalEventDefPb put_external_event_def = 8;
        RunWfPb run_wf = 9;
        PutExternalEventPb put_external_event = 10;
        StopWfRunPb stop_wf_run = 11;
        ResumeWfRunPb resume_wf_run = 12;
        SleepNodeMaturedPb sleep_node_matured = 13;
        DeleteWfRunPb delete_wf_run = 14;
        DeleteWfSpecPb delete_wf_spec = 15;
        DeleteTaskDefPb delete_task_def = 16;
        DeleteExternalEventDefPb delete_external_event_def = 17;
        ExternalEventNodeTimeoutPb external_event_timeout = 18;
        TaskWorkerHeartBeatPb task_worker_heart_beat = 19;
        DeleteExternalEventPb delete_external_event = 20;
    }
}


// This is for LHTimers.

message LHTimerPb {
    google.protobuf.Timestamp maturation_time = 1;
    string key = 2;
    string topic = 3;
    bytes payload = 4;
}
